{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert a PyTorch model to Tensorflow using ONNX\n",
    "\n",
    "In this tutorial, we will show you how to export a model defined in PyTorch to ONNX and then import the ONNX model into Tensorflow to run it. We will also show you how to save this Tensorflow model into a file for later use.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installations\n",
    "\n",
    "First let's install [ONNX](https://github.com/onnx/onnx), [PyTorch](https://github.com/pytorch/pytorch), and [Tensorflow](https://github.com/tensorflow/tensorflow) by following the instructions on each of their repository.\n",
    "\n",
    "Next install [onnx-tensorflow](https://github.com/onnx/onnx-tensorflow) by the following commands:\n",
    "```\n",
    "git clone git@github.com:onnx/onnx-tensorflow.git && cd onnx-tensorflow\n",
    "pip install -e .\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define model\n",
    "\n",
    "In this tutorial we are going to use the [MNIST model](https://github.com/pytorch/examples/tree/master/mnist) from PyTorch examples.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n",
    "        self.conv2_drop = nn.Dropout2d()\n",
    "        self.fc1 = nn.Linear(320, 50)\n",
    "        self.fc2 = nn.Linear(50, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
    "        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n",
    "        x = x.view(-1, 320)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.fc2(x)\n",
    "        return F.log_softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and test model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Processing...\n",
      "Done!\n",
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.342948\n",
      "Train Epoch: 1 [19200/60000 (32%)]\tLoss: 0.945489\n",
      "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 0.590510\n",
      "Train Epoch: 1 [57600/60000 (96%)]\tLoss: 0.371047\n",
      "\n",
      "Test set: Average loss: 0.2032, Accuracy: 9407/10000 (94%)\n",
      "\n",
      "Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.371472\n",
      "Train Epoch: 2 [19200/60000 (32%)]\tLoss: 0.316857\n",
      "Train Epoch: 2 [38400/60000 (64%)]\tLoss: 0.205765\n",
      "Train Epoch: 2 [57600/60000 (96%)]\tLoss: 0.423041\n",
      "\n",
      "Test set: Average loss: 0.1220, Accuracy: 9617/10000 (96%)\n",
      "\n",
      "Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.489221\n",
      "Train Epoch: 3 [19200/60000 (32%)]\tLoss: 0.504540\n",
      "Train Epoch: 3 [38400/60000 (64%)]\tLoss: 0.205699\n",
      "Train Epoch: 3 [57600/60000 (96%)]\tLoss: 0.385294\n",
      "\n",
      "Test set: Average loss: 0.1024, Accuracy: 9676/10000 (97%)\n",
      "\n",
      "Train Epoch: 4 [0/60000 (0%)]\tLoss: 0.399744\n",
      "Train Epoch: 4 [19200/60000 (32%)]\tLoss: 0.288648\n",
      "Train Epoch: 4 [38400/60000 (64%)]\tLoss: 0.144865\n",
      "Train Epoch: 4 [57600/60000 (96%)]\tLoss: 0.082947\n",
      "\n",
      "Test set: Average loss: 0.0811, Accuracy: 9746/10000 (97%)\n",
      "\n",
      "Train Epoch: 5 [0/60000 (0%)]\tLoss: 0.245548\n",
      "Train Epoch: 5 [19200/60000 (32%)]\tLoss: 0.214518\n",
      "Train Epoch: 5 [38400/60000 (64%)]\tLoss: 0.183569\n",
      "Train Epoch: 5 [57600/60000 (96%)]\tLoss: 0.234130\n",
      "\n",
      "Test set: Average loss: 0.0762, Accuracy: 9766/10000 (98%)\n",
      "\n",
      "Train Epoch: 6 [0/60000 (0%)]\tLoss: 0.212589\n",
      "Train Epoch: 6 [19200/60000 (32%)]\tLoss: 0.330691\n",
      "Train Epoch: 6 [38400/60000 (64%)]\tLoss: 0.356382\n",
      "Train Epoch: 6 [57600/60000 (96%)]\tLoss: 0.147715\n",
      "\n",
      "Test set: Average loss: 0.0652, Accuracy: 9792/10000 (98%)\n",
      "\n",
      "Train Epoch: 7 [0/60000 (0%)]\tLoss: 0.237580\n",
      "Train Epoch: 7 [19200/60000 (32%)]\tLoss: 0.094254\n",
      "Train Epoch: 7 [38400/60000 (64%)]\tLoss: 0.111272\n",
      "Train Epoch: 7 [57600/60000 (96%)]\tLoss: 0.313418\n",
      "\n",
      "Test set: Average loss: 0.0609, Accuracy: 9811/10000 (98%)\n",
      "\n",
      "Train Epoch: 8 [0/60000 (0%)]\tLoss: 0.217023\n",
      "Train Epoch: 8 [19200/60000 (32%)]\tLoss: 0.380819\n",
      "Train Epoch: 8 [38400/60000 (64%)]\tLoss: 0.073535\n",
      "Train Epoch: 8 [57600/60000 (96%)]\tLoss: 0.114267\n",
      "\n",
      "Test set: Average loss: 0.0605, Accuracy: 9816/10000 (98%)\n",
      "\n",
      "Train Epoch: 9 [0/60000 (0%)]\tLoss: 0.085590\n",
      "Train Epoch: 9 [19200/60000 (32%)]\tLoss: 0.440782\n",
      "Train Epoch: 9 [38400/60000 (64%)]\tLoss: 0.174895\n",
      "Train Epoch: 9 [57600/60000 (96%)]\tLoss: 0.211528\n",
      "\n",
      "Test set: Average loss: 0.0532, Accuracy: 9835/10000 (98%)\n",
      "\n",
      "Train Epoch: 10 [0/60000 (0%)]\tLoss: 0.020839\n",
      "Train Epoch: 10 [19200/60000 (32%)]\tLoss: 0.080268\n",
      "Train Epoch: 10 [38400/60000 (64%)]\tLoss: 0.183083\n",
      "Train Epoch: 10 [57600/60000 (96%)]\tLoss: 0.125454\n",
      "\n",
      "Test set: Average loss: 0.0497, Accuracy: 9849/10000 (98%)\n",
      "\n",
      "Train Epoch: 11 [0/60000 (0%)]\tLoss: 0.082064\n",
      "Train Epoch: 11 [19200/60000 (32%)]\tLoss: 0.276986\n",
      "Train Epoch: 11 [38400/60000 (64%)]\tLoss: 0.292398\n",
      "Train Epoch: 11 [57600/60000 (96%)]\tLoss: 0.158535\n",
      "\n",
      "Test set: Average loss: 0.0474, Accuracy: 9853/10000 (99%)\n",
      "\n",
      "Train Epoch: 12 [0/60000 (0%)]\tLoss: 0.079488\n",
      "Train Epoch: 12 [19200/60000 (32%)]\tLoss: 0.044621\n",
      "Train Epoch: 12 [38400/60000 (64%)]\tLoss: 0.037131\n",
      "Train Epoch: 12 [57600/60000 (96%)]\tLoss: 0.213540\n",
      "\n",
      "Test set: Average loss: 0.0502, Accuracy: 9838/10000 (98%)\n",
      "\n",
      "Train Epoch: 13 [0/60000 (0%)]\tLoss: 0.089334\n",
      "Train Epoch: 13 [19200/60000 (32%)]\tLoss: 0.057157\n",
      "Train Epoch: 13 [38400/60000 (64%)]\tLoss: 0.065857\n",
      "Train Epoch: 13 [57600/60000 (96%)]\tLoss: 0.081137\n",
      "\n",
      "Test set: Average loss: 0.0461, Accuracy: 9845/10000 (98%)\n",
      "\n",
      "Train Epoch: 14 [0/60000 (0%)]\tLoss: 0.138673\n",
      "Train Epoch: 14 [19200/60000 (32%)]\tLoss: 0.054619\n",
      "Train Epoch: 14 [38400/60000 (64%)]\tLoss: 0.107671\n",
      "Train Epoch: 14 [57600/60000 (96%)]\tLoss: 0.399239\n",
      "\n",
      "Test set: Average loss: 0.0432, Accuracy: 9857/10000 (99%)\n",
      "\n",
      "Train Epoch: 15 [0/60000 (0%)]\tLoss: 0.283873\n",
      "Train Epoch: 15 [19200/60000 (32%)]\tLoss: 0.119616\n",
      "Train Epoch: 15 [38400/60000 (64%)]\tLoss: 0.330997\n",
      "Train Epoch: 15 [57600/60000 (96%)]\tLoss: 0.155137\n",
      "\n",
      "Test set: Average loss: 0.0448, Accuracy: 9863/10000 (99%)\n",
      "\n",
      "Train Epoch: 16 [0/60000 (0%)]\tLoss: 0.131139\n",
      "Train Epoch: 16 [19200/60000 (32%)]\tLoss: 0.068266\n",
      "Train Epoch: 16 [38400/60000 (64%)]\tLoss: 0.167868\n",
      "Train Epoch: 16 [57600/60000 (96%)]\tLoss: 0.082237\n",
      "\n",
      "Test set: Average loss: 0.0424, Accuracy: 9864/10000 (99%)\n",
      "\n",
      "Train Epoch: 17 [0/60000 (0%)]\tLoss: 0.069797\n",
      "Train Epoch: 17 [19200/60000 (32%)]\tLoss: 0.116358\n",
      "Train Epoch: 17 [38400/60000 (64%)]\tLoss: 0.099303\n",
      "Train Epoch: 17 [57600/60000 (96%)]\tLoss: 0.090594\n",
      "\n",
      "Test set: Average loss: 0.0398, Accuracy: 9875/10000 (99%)\n",
      "\n",
      "Train Epoch: 18 [0/60000 (0%)]\tLoss: 0.082352\n",
      "Train Epoch: 18 [19200/60000 (32%)]\tLoss: 0.065758\n",
      "Train Epoch: 18 [38400/60000 (64%)]\tLoss: 0.062641\n",
      "Train Epoch: 18 [57600/60000 (96%)]\tLoss: 0.134366\n",
      "\n",
      "Test set: Average loss: 0.0409, Accuracy: 9874/10000 (99%)\n",
      "\n",
      "Train Epoch: 19 [0/60000 (0%)]\tLoss: 0.046955\n",
      "Train Epoch: 19 [19200/60000 (32%)]\tLoss: 0.042944\n",
      "Train Epoch: 19 [38400/60000 (64%)]\tLoss: 0.163447\n",
      "Train Epoch: 19 [57600/60000 (96%)]\tLoss: 0.056221\n",
      "\n",
      "Test set: Average loss: 0.0391, Accuracy: 9883/10000 (99%)\n",
      "\n",
      "Train Epoch: 20 [0/60000 (0%)]\tLoss: 0.174666\n",
      "Train Epoch: 20 [19200/60000 (32%)]\tLoss: 0.217916\n",
      "Train Epoch: 20 [38400/60000 (64%)]\tLoss: 0.109612\n",
      "Train Epoch: 20 [57600/60000 (96%)]\tLoss: 0.052521\n",
      "\n",
      "Test set: Average loss: 0.0389, Accuracy: 9883/10000 (99%)\n",
      "\n",
      "Train Epoch: 21 [0/60000 (0%)]\tLoss: 0.176766\n",
      "Train Epoch: 21 [19200/60000 (32%)]\tLoss: 0.065771\n",
      "Train Epoch: 21 [38400/60000 (64%)]\tLoss: 0.153285\n",
      "Train Epoch: 21 [57600/60000 (96%)]\tLoss: 0.105379\n",
      "\n",
      "Test set: Average loss: 0.0378, Accuracy: 9881/10000 (99%)\n",
      "\n",
      "Train Epoch: 22 [0/60000 (0%)]\tLoss: 0.035272\n",
      "Train Epoch: 22 [19200/60000 (32%)]\tLoss: 0.148689\n",
      "Train Epoch: 22 [38400/60000 (64%)]\tLoss: 0.174996\n",
      "Train Epoch: 22 [57600/60000 (96%)]\tLoss: 0.310371\n",
      "\n",
      "Test set: Average loss: 0.0388, Accuracy: 9883/10000 (99%)\n",
      "\n",
      "Train Epoch: 23 [0/60000 (0%)]\tLoss: 0.094962\n",
      "Train Epoch: 23 [19200/60000 (32%)]\tLoss: 0.030179\n",
      "Train Epoch: 23 [38400/60000 (64%)]\tLoss: 0.039277\n",
      "Train Epoch: 23 [57600/60000 (96%)]\tLoss: 0.106372\n",
      "\n",
      "Test set: Average loss: 0.0362, Accuracy: 9892/10000 (99%)\n",
      "\n",
      "Train Epoch: 24 [0/60000 (0%)]\tLoss: 0.050780\n",
      "Train Epoch: 24 [19200/60000 (32%)]\tLoss: 0.101291\n",
      "Train Epoch: 24 [38400/60000 (64%)]\tLoss: 0.066187\n",
      "Train Epoch: 24 [57600/60000 (96%)]\tLoss: 0.072713\n",
      "\n",
      "Test set: Average loss: 0.0370, Accuracy: 9882/10000 (99%)\n",
      "\n",
      "Train Epoch: 25 [0/60000 (0%)]\tLoss: 0.179445\n",
      "Train Epoch: 25 [19200/60000 (32%)]\tLoss: 0.166139\n",
      "Train Epoch: 25 [38400/60000 (64%)]\tLoss: 0.096020\n",
      "Train Epoch: 25 [57600/60000 (96%)]\tLoss: 0.043286\n",
      "\n",
      "Test set: Average loss: 0.0366, Accuracy: 9883/10000 (99%)\n",
      "\n",
      "Train Epoch: 26 [0/60000 (0%)]\tLoss: 0.225514\n",
      "Train Epoch: 26 [19200/60000 (32%)]\tLoss: 0.109221\n",
      "Train Epoch: 26 [38400/60000 (64%)]\tLoss: 0.049721\n",
      "Train Epoch: 26 [57600/60000 (96%)]\tLoss: 0.142338\n",
      "\n",
      "Test set: Average loss: 0.0346, Accuracy: 9892/10000 (99%)\n",
      "\n",
      "Train Epoch: 27 [0/60000 (0%)]\tLoss: 0.227106\n",
      "Train Epoch: 27 [19200/60000 (32%)]\tLoss: 0.087923\n",
      "Train Epoch: 27 [38400/60000 (64%)]\tLoss: 0.062280\n",
      "Train Epoch: 27 [57600/60000 (96%)]\tLoss: 0.202031\n",
      "\n",
      "Test set: Average loss: 0.0385, Accuracy: 9884/10000 (99%)\n",
      "\n",
      "Train Epoch: 28 [0/60000 (0%)]\tLoss: 0.074609\n",
      "Train Epoch: 28 [19200/60000 (32%)]\tLoss: 0.294575\n",
      "Train Epoch: 28 [38400/60000 (64%)]\tLoss: 0.106352\n",
      "Train Epoch: 28 [57600/60000 (96%)]\tLoss: 0.138919\n",
      "\n",
      "Test set: Average loss: 0.0357, Accuracy: 9901/10000 (99%)\n",
      "\n",
      "Train Epoch: 29 [0/60000 (0%)]\tLoss: 0.065013\n",
      "Train Epoch: 29 [19200/60000 (32%)]\tLoss: 0.132381\n",
      "Train Epoch: 29 [38400/60000 (64%)]\tLoss: 0.065967\n",
      "Train Epoch: 29 [57600/60000 (96%)]\tLoss: 0.093698\n",
      "\n",
      "Test set: Average loss: 0.0382, Accuracy: 9880/10000 (99%)\n",
      "\n",
      "Train Epoch: 30 [0/60000 (0%)]\tLoss: 0.068083\n",
      "Train Epoch: 30 [19200/60000 (32%)]\tLoss: 0.299544\n",
      "Train Epoch: 30 [38400/60000 (64%)]\tLoss: 0.158337\n",
      "Train Epoch: 30 [57600/60000 (96%)]\tLoss: 0.127789\n",
      "\n",
      "Test set: Average loss: 0.0353, Accuracy: 9888/10000 (99%)\n",
      "\n",
      "Train Epoch: 31 [0/60000 (0%)]\tLoss: 0.088943\n",
      "Train Epoch: 31 [19200/60000 (32%)]\tLoss: 0.158826\n",
      "Train Epoch: 31 [38400/60000 (64%)]\tLoss: 0.162431\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 31 [57600/60000 (96%)]\tLoss: 0.199190\n",
      "\n",
      "Test set: Average loss: 0.0358, Accuracy: 9894/10000 (99%)\n",
      "\n",
      "Train Epoch: 32 [0/60000 (0%)]\tLoss: 0.112976\n",
      "Train Epoch: 32 [19200/60000 (32%)]\tLoss: 0.080692\n",
      "Train Epoch: 32 [38400/60000 (64%)]\tLoss: 0.531600\n",
      "Train Epoch: 32 [57600/60000 (96%)]\tLoss: 0.092054\n",
      "\n",
      "Test set: Average loss: 0.0364, Accuracy: 9888/10000 (99%)\n",
      "\n",
      "Train Epoch: 33 [0/60000 (0%)]\tLoss: 0.112255\n",
      "Train Epoch: 33 [19200/60000 (32%)]\tLoss: 0.173839\n",
      "Train Epoch: 33 [38400/60000 (64%)]\tLoss: 0.100733\n",
      "Train Epoch: 33 [57600/60000 (96%)]\tLoss: 0.212895\n",
      "\n",
      "Test set: Average loss: 0.0338, Accuracy: 9888/10000 (99%)\n",
      "\n",
      "Train Epoch: 34 [0/60000 (0%)]\tLoss: 0.181373\n",
      "Train Epoch: 34 [19200/60000 (32%)]\tLoss: 0.091187\n",
      "Train Epoch: 34 [38400/60000 (64%)]\tLoss: 0.146965\n",
      "Train Epoch: 34 [57600/60000 (96%)]\tLoss: 0.030407\n",
      "\n",
      "Test set: Average loss: 0.0343, Accuracy: 9891/10000 (99%)\n",
      "\n",
      "Train Epoch: 35 [0/60000 (0%)]\tLoss: 0.203500\n",
      "Train Epoch: 35 [19200/60000 (32%)]\tLoss: 0.347259\n",
      "Train Epoch: 35 [38400/60000 (64%)]\tLoss: 0.260525\n",
      "Train Epoch: 35 [57600/60000 (96%)]\tLoss: 0.175972\n",
      "\n",
      "Test set: Average loss: 0.0358, Accuracy: 9895/10000 (99%)\n",
      "\n",
      "Train Epoch: 36 [0/60000 (0%)]\tLoss: 0.080689\n",
      "Train Epoch: 36 [19200/60000 (32%)]\tLoss: 0.094646\n",
      "Train Epoch: 36 [38400/60000 (64%)]\tLoss: 0.118065\n",
      "Train Epoch: 36 [57600/60000 (96%)]\tLoss: 0.080132\n",
      "\n",
      "Test set: Average loss: 0.0350, Accuracy: 9895/10000 (99%)\n",
      "\n",
      "Train Epoch: 37 [0/60000 (0%)]\tLoss: 0.100757\n",
      "Train Epoch: 37 [19200/60000 (32%)]\tLoss: 0.078236\n",
      "Train Epoch: 37 [38400/60000 (64%)]\tLoss: 0.032407\n",
      "Train Epoch: 37 [57600/60000 (96%)]\tLoss: 0.087835\n",
      "\n",
      "Test set: Average loss: 0.0349, Accuracy: 9894/10000 (99%)\n",
      "\n",
      "Train Epoch: 38 [0/60000 (0%)]\tLoss: 0.020575\n",
      "Train Epoch: 38 [19200/60000 (32%)]\tLoss: 0.174518\n",
      "Train Epoch: 38 [38400/60000 (64%)]\tLoss: 0.021365\n",
      "Train Epoch: 38 [57600/60000 (96%)]\tLoss: 0.085258\n",
      "\n",
      "Test set: Average loss: 0.0325, Accuracy: 9892/10000 (99%)\n",
      "\n",
      "Train Epoch: 39 [0/60000 (0%)]\tLoss: 0.118623\n",
      "Train Epoch: 39 [19200/60000 (32%)]\tLoss: 0.110365\n",
      "Train Epoch: 39 [38400/60000 (64%)]\tLoss: 0.213334\n",
      "Train Epoch: 39 [57600/60000 (96%)]\tLoss: 0.089908\n",
      "\n",
      "Test set: Average loss: 0.0344, Accuracy: 9890/10000 (99%)\n",
      "\n",
      "Train Epoch: 40 [0/60000 (0%)]\tLoss: 0.212801\n",
      "Train Epoch: 40 [19200/60000 (32%)]\tLoss: 0.143369\n",
      "Train Epoch: 40 [38400/60000 (64%)]\tLoss: 0.170997\n",
      "Train Epoch: 40 [57600/60000 (96%)]\tLoss: 0.099105\n",
      "\n",
      "Test set: Average loss: 0.0342, Accuracy: 9893/10000 (99%)\n",
      "\n",
      "Train Epoch: 41 [0/60000 (0%)]\tLoss: 0.175358\n",
      "Train Epoch: 41 [19200/60000 (32%)]\tLoss: 0.117286\n",
      "Train Epoch: 41 [38400/60000 (64%)]\tLoss: 0.212153\n",
      "Train Epoch: 41 [57600/60000 (96%)]\tLoss: 0.038004\n",
      "\n",
      "Test set: Average loss: 0.0314, Accuracy: 9899/10000 (99%)\n",
      "\n",
      "Train Epoch: 42 [0/60000 (0%)]\tLoss: 0.147026\n",
      "Train Epoch: 42 [19200/60000 (32%)]\tLoss: 0.073230\n",
      "Train Epoch: 42 [38400/60000 (64%)]\tLoss: 0.131966\n",
      "Train Epoch: 42 [57600/60000 (96%)]\tLoss: 0.118915\n",
      "\n",
      "Test set: Average loss: 0.0321, Accuracy: 9901/10000 (99%)\n",
      "\n",
      "Train Epoch: 43 [0/60000 (0%)]\tLoss: 0.033298\n",
      "Train Epoch: 43 [19200/60000 (32%)]\tLoss: 0.043562\n",
      "Train Epoch: 43 [38400/60000 (64%)]\tLoss: 0.055704\n",
      "Train Epoch: 43 [57600/60000 (96%)]\tLoss: 0.157554\n",
      "\n",
      "Test set: Average loss: 0.0313, Accuracy: 9905/10000 (99%)\n",
      "\n",
      "Train Epoch: 44 [0/60000 (0%)]\tLoss: 0.099271\n",
      "Train Epoch: 44 [19200/60000 (32%)]\tLoss: 0.302592\n",
      "Train Epoch: 44 [38400/60000 (64%)]\tLoss: 0.059918\n",
      "Train Epoch: 44 [57600/60000 (96%)]\tLoss: 0.125791\n",
      "\n",
      "Test set: Average loss: 0.0316, Accuracy: 9899/10000 (99%)\n",
      "\n",
      "Train Epoch: 45 [0/60000 (0%)]\tLoss: 0.121331\n",
      "Train Epoch: 45 [19200/60000 (32%)]\tLoss: 0.087672\n",
      "Train Epoch: 45 [38400/60000 (64%)]\tLoss: 0.027022\n",
      "Train Epoch: 45 [57600/60000 (96%)]\tLoss: 0.137008\n",
      "\n",
      "Test set: Average loss: 0.0312, Accuracy: 9904/10000 (99%)\n",
      "\n",
      "Train Epoch: 46 [0/60000 (0%)]\tLoss: 0.094723\n",
      "Train Epoch: 46 [19200/60000 (32%)]\tLoss: 0.177073\n",
      "Train Epoch: 46 [38400/60000 (64%)]\tLoss: 0.022148\n",
      "Train Epoch: 46 [57600/60000 (96%)]\tLoss: 0.274569\n",
      "\n",
      "Test set: Average loss: 0.0321, Accuracy: 9900/10000 (99%)\n",
      "\n",
      "Train Epoch: 47 [0/60000 (0%)]\tLoss: 0.091959\n",
      "Train Epoch: 47 [19200/60000 (32%)]\tLoss: 0.146935\n",
      "Train Epoch: 47 [38400/60000 (64%)]\tLoss: 0.142358\n",
      "Train Epoch: 47 [57600/60000 (96%)]\tLoss: 0.169541\n",
      "\n",
      "Test set: Average loss: 0.0358, Accuracy: 9884/10000 (99%)\n",
      "\n",
      "Train Epoch: 48 [0/60000 (0%)]\tLoss: 0.111446\n",
      "Train Epoch: 48 [19200/60000 (32%)]\tLoss: 0.040825\n",
      "Train Epoch: 48 [38400/60000 (64%)]\tLoss: 0.009231\n",
      "Train Epoch: 48 [57600/60000 (96%)]\tLoss: 0.124508\n",
      "\n",
      "Test set: Average loss: 0.0325, Accuracy: 9894/10000 (99%)\n",
      "\n",
      "Train Epoch: 49 [0/60000 (0%)]\tLoss: 0.046256\n",
      "Train Epoch: 49 [19200/60000 (32%)]\tLoss: 0.182447\n",
      "Train Epoch: 49 [38400/60000 (64%)]\tLoss: 0.030951\n",
      "Train Epoch: 49 [57600/60000 (96%)]\tLoss: 0.140656\n",
      "\n",
      "Test set: Average loss: 0.0311, Accuracy: 9900/10000 (99%)\n",
      "\n",
      "Train Epoch: 50 [0/60000 (0%)]\tLoss: 0.138393\n",
      "Train Epoch: 50 [19200/60000 (32%)]\tLoss: 0.079600\n",
      "Train Epoch: 50 [38400/60000 (64%)]\tLoss: 0.106838\n",
      "Train Epoch: 50 [57600/60000 (96%)]\tLoss: 0.302059\n",
      "\n",
      "Test set: Average loss: 0.0329, Accuracy: 9897/10000 (99%)\n",
      "\n",
      "Train Epoch: 51 [0/60000 (0%)]\tLoss: 0.047996\n",
      "Train Epoch: 51 [19200/60000 (32%)]\tLoss: 0.110355\n",
      "Train Epoch: 51 [38400/60000 (64%)]\tLoss: 0.138583\n",
      "Train Epoch: 51 [57600/60000 (96%)]\tLoss: 0.012788\n",
      "\n",
      "Test set: Average loss: 0.0341, Accuracy: 9891/10000 (99%)\n",
      "\n",
      "Train Epoch: 52 [0/60000 (0%)]\tLoss: 0.006743\n",
      "Train Epoch: 52 [19200/60000 (32%)]\tLoss: 0.187683\n",
      "Train Epoch: 52 [38400/60000 (64%)]\tLoss: 0.086446\n",
      "Train Epoch: 52 [57600/60000 (96%)]\tLoss: 0.088116\n",
      "\n",
      "Test set: Average loss: 0.0311, Accuracy: 9903/10000 (99%)\n",
      "\n",
      "Train Epoch: 53 [0/60000 (0%)]\tLoss: 0.088756\n",
      "Train Epoch: 53 [19200/60000 (32%)]\tLoss: 0.130021\n",
      "Train Epoch: 53 [38400/60000 (64%)]\tLoss: 0.109240\n",
      "Train Epoch: 53 [57600/60000 (96%)]\tLoss: 0.067128\n",
      "\n",
      "Test set: Average loss: 0.0312, Accuracy: 9906/10000 (99%)\n",
      "\n",
      "Train Epoch: 54 [0/60000 (0%)]\tLoss: 0.015841\n",
      "Train Epoch: 54 [19200/60000 (32%)]\tLoss: 0.061344\n",
      "Train Epoch: 54 [38400/60000 (64%)]\tLoss: 0.089854\n",
      "Train Epoch: 54 [57600/60000 (96%)]\tLoss: 0.040337\n",
      "\n",
      "Test set: Average loss: 0.0304, Accuracy: 9906/10000 (99%)\n",
      "\n",
      "Train Epoch: 55 [0/60000 (0%)]\tLoss: 0.100276\n",
      "Train Epoch: 55 [19200/60000 (32%)]\tLoss: 0.041967\n",
      "Train Epoch: 55 [38400/60000 (64%)]\tLoss: 0.047300\n",
      "Train Epoch: 55 [57600/60000 (96%)]\tLoss: 0.079063\n",
      "\n",
      "Test set: Average loss: 0.0318, Accuracy: 9897/10000 (99%)\n",
      "\n",
      "Train Epoch: 56 [0/60000 (0%)]\tLoss: 0.156676\n",
      "Train Epoch: 56 [19200/60000 (32%)]\tLoss: 0.057480\n",
      "Train Epoch: 56 [38400/60000 (64%)]\tLoss: 0.060755\n",
      "Train Epoch: 56 [57600/60000 (96%)]\tLoss: 0.205643\n",
      "\n",
      "Test set: Average loss: 0.0321, Accuracy: 9895/10000 (99%)\n",
      "\n",
      "Train Epoch: 57 [0/60000 (0%)]\tLoss: 0.083001\n",
      "Train Epoch: 57 [19200/60000 (32%)]\tLoss: 0.082778\n",
      "Train Epoch: 57 [38400/60000 (64%)]\tLoss: 0.104672\n",
      "Train Epoch: 57 [57600/60000 (96%)]\tLoss: 0.133364\n",
      "\n",
      "Test set: Average loss: 0.0311, Accuracy: 9906/10000 (99%)\n",
      "\n",
      "Train Epoch: 58 [0/60000 (0%)]\tLoss: 0.061462\n",
      "Train Epoch: 58 [19200/60000 (32%)]\tLoss: 0.016971\n",
      "Train Epoch: 58 [38400/60000 (64%)]\tLoss: 0.038841\n",
      "Train Epoch: 58 [57600/60000 (96%)]\tLoss: 0.052291\n",
      "\n",
      "Test set: Average loss: 0.0300, Accuracy: 9903/10000 (99%)\n",
      "\n",
      "Train Epoch: 59 [0/60000 (0%)]\tLoss: 0.140371\n",
      "Train Epoch: 59 [19200/60000 (32%)]\tLoss: 0.260545\n",
      "Train Epoch: 59 [38400/60000 (64%)]\tLoss: 0.077362\n",
      "Train Epoch: 59 [57600/60000 (96%)]\tLoss: 0.197628\n",
      "\n",
      "Test set: Average loss: 0.0329, Accuracy: 9899/10000 (99%)\n",
      "\n",
      "Train Epoch: 60 [0/60000 (0%)]\tLoss: 0.067552\n",
      "Train Epoch: 60 [19200/60000 (32%)]\tLoss: 0.080549\n",
      "Train Epoch: 60 [38400/60000 (64%)]\tLoss: 0.055083\n",
      "Train Epoch: 60 [57600/60000 (96%)]\tLoss: 0.228645\n",
      "\n",
      "Test set: Average loss: 0.0308, Accuracy: 9909/10000 (99%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "def train(args, model, device, train_loader, optimizer, epoch):\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = F.nll_loss(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_idx % args.log_interval == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.item()))\n",
    "\n",
    "def test(args, model, device, test_loader):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            test_loss += F.nll_loss(output, target, reduction='sum').item() # sum up batch loss\n",
    "            pred = output.max(1, keepdim=True)[1] # get the index of the max log-probability\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        test_loss, correct, len(test_loader.dataset),\n",
    "        100. * correct / len(test_loader.dataset)))\n",
    "    \n",
    "# Training settings\n",
    "parser = argparse.ArgumentParser(description='PyTorch MNIST Example')\n",
    "parser.add_argument('--batch-size', type=int, default=64, metavar='N',\n",
    "                    help='input batch size for training (default: 64)')\n",
    "parser.add_argument('--test-batch-size', type=int, default=1000, metavar='N',\n",
    "                    help='input batch size for testing (default: 1000)')\n",
    "parser.add_argument('--epochs', type=int, default=10, metavar='N',\n",
    "                    help='number of epochs to train (default: 10)')\n",
    "parser.add_argument('--lr', type=float, default=0.01, metavar='LR',\n",
    "                    help='learning rate (default: 0.01)')\n",
    "parser.add_argument('--momentum', type=float, default=0.5, metavar='M',\n",
    "                    help='SGD momentum (default: 0.5)')\n",
    "parser.add_argument('--no-cuda', action='store_true', default=False,\n",
    "                    help='disables CUDA training')\n",
    "parser.add_argument('--seed', type=int, default=1, metavar='S',\n",
    "                    help='random seed (default: 1)')\n",
    "parser.add_argument('--log-interval', type=int, default=10, metavar='N',\n",
    "                    help='how many batches to wait before logging training status')\n",
    "\n",
    "# Train this model with 60 epochs and after process every 300 batches log the train status \n",
    "args = parser.parse_args(['--epochs', '60', '--log-interval', '300'])\n",
    "\n",
    "use_cuda = not args.no_cuda and torch.cuda.is_available()\n",
    "\n",
    "torch.manual_seed(args.seed)\n",
    "\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "\n",
    "kwargs = {'num_workers': 1, 'pin_memory': True} if use_cuda else {}\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST('../data', train=True, download=True,\n",
    "                    transform=transforms.Compose([\n",
    "                        transforms.ToTensor(),\n",
    "                        transforms.Normalize((0.1307,), (0.3081,))\n",
    "                    ])),\n",
    "    batch_size=args.batch_size, shuffle=True, **kwargs)\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST('../data', train=False, transform=transforms.Compose([\n",
    "                        transforms.ToTensor(),\n",
    "                        transforms.Normalize((0.1307,), (0.3081,))\n",
    "                    ])),\n",
    "    batch_size=args.test_batch_size, shuffle=True, **kwargs)\n",
    "\n",
    "\n",
    "model = Net().to(device)\n",
    "optimizer = optim.SGD(model.parameters(), lr=args.lr, momentum=args.momentum)\n",
    "\n",
    "for epoch in range(1, args.epochs + 1):\n",
    "    train(args, model, device, train_loader, optimizer, epoch)\n",
    "    test(args, model, device, test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the trained model to a file\n",
    "torch.save(model.state_dict(), 'mnist.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export the trained model to ONNX \n",
    "In order to export the model, it needs to run the model once and save this resulting traced model to a ONNX file. Therefore, we need to provide the input for the MNIST model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.autograd import Variable\n",
    "\n",
    "# Load the trained model from file\n",
    "trained_model = Net()\n",
    "trained_model.load_state_dict(torch.load('mnist.pth'))\n",
    "\n",
    "# Export the trained model to ONNX\n",
    "dummy_input = Variable(torch.randn(1, 1, 28, 28))\n",
    "torch.onnx.export(trained_model, dummy_input, \"mnist.onnx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import the ONNX model to Tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fail to get since_version of Expand in domain `` with max_inclusive_version=7. Set to 1.\n"
     ]
    }
   ],
   "source": [
    "import onnx\n",
    "from onnx_tf.backend import prepare\n",
    "\n",
    "# Load the ONNX file\n",
    "model = onnx.load('mnist.onnx')\n",
    "\n",
    "# Verify the ONNX model is well formed\n",
    "onnx.checker.check_model(model)\n",
    "\n",
    "# Import the ONNX model to Tensorflow\n",
    "tf_rep = prepare(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's explore the tf_rep object return from onnx.tf.backend.prepare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs: ['0']\n",
      "outputs: ['22']\n",
      "tensor_dict:\n",
      "{'12': <tf.Tensor 'Add_1:0' shape=(1, 20, 8, 8) dtype=float32>, '17': <tf.Tensor 'add_3:0' shape=(1, 50) dtype=float32>, '9': <tf.Tensor 'Add:0' shape=(1, 10, 24, 24) dtype=float32>, '3': <tf.Tensor 'Const_2:0' shape=(20, 10, 5, 5) dtype=float32>, '5': <tf.Tensor 'Const_4:0' shape=(50, 320) dtype=float32>, '4': <tf.Tensor 'Const_3:0' shape=(20,) dtype=float32>, '21': <tf.Tensor 'add_4:0' shape=(1, 10) dtype=float32>, '1': <tf.Tensor 'Const:0' shape=(10, 1, 5, 5) dtype=float32>, '18': <tf.Tensor 'Relu_2:0' shape=(1, 50) dtype=float32>, '2': <tf.Tensor 'Const_1:0' shape=(10,) dtype=float32>, '14': <tf.Tensor 'Relu_1:0' shape=(1, 20, 4, 4) dtype=float32>, '15': <tf.Tensor 'Const_14:0' shape=(2,) dtype=int64>, '13': <tf.Tensor 'max_pool_1:0' shape=(1, 20, 4, 4) dtype=float32>, '16': <tf.Tensor 'Reshape:0' shape=(1, 320) dtype=float32>, '11': <tf.Tensor 'Relu:0' shape=(1, 10, 12, 12) dtype=float32>, '6': <tf.Tensor 'Const_5:0' shape=(50,) dtype=float32>, '8': <tf.Tensor 'Const_7:0' shape=(10,) dtype=float32>, '0': <tf.Tensor '0:0' shape=(1, 1, 28, 28) dtype=float32>, '19': <tf.Tensor 'Relu_2:0' shape=(1, 50) dtype=float32>, '10': <tf.Tensor 'max_pool:0' shape=(1, 10, 12, 12) dtype=float32>, '22': <tf.Tensor 'LogSoftmax:0' shape=(1, 10) dtype=float32>, '7': <tf.Tensor 'Const_6:0' shape=(10, 50) dtype=float32>}\n"
     ]
    }
   ],
   "source": [
    "# Input nodes to the model\n",
    "print('inputs:', tf_rep.inputs)\n",
    "\n",
    "# Output nodes from the model\n",
    "print('outputs:', tf_rep.outputs)\n",
    "\n",
    "# All nodes in the model\n",
    "print('tensor_dict:')\n",
    "print(tf_rep.tensor_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the model in Tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image 1:\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAABV0lEQVR4nH2SvUvDUBTFz2tfTP2EWmx1FKyKtIIIik4FQRB00MGhIA4O9Y8Q9E9wEkGkSzedCjqKS6VgUXCyIH4MpZVWKtjEGJJclyTGlNczPC7n9y73ct5jtRiE4m6lHD9x8IHUfI9rMbdTv20GLUu5ed+fcmmNbFmaqirK5+NJquRYf9C50zhaUew64F+CDa71X9t1GwSLrF4KIeTZkhgGIpYYQhrqACF3gmYn6MzkHk+/ghRLAEa5DSpn+THJrCbTw3XND5s7ocwEIzWb3pAXHNPO9msvXtaIiN4upuMZX7ZmZWtcBoCR3pfl+5//nd+nc89ERMbB4mGlsN4gIiLnsa16Lr8da73eJZcmw8aumQU8P8H6KBSDPDo6Ew0CD5vnCS8EaXUKdPeFAEAvhpOemT7pKhGRNyGPJEmYrSNOIAEixrvABJCBV2EQGAEMsE9GjADGWr9+T83NEo+4sgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=28x28 at 0x7F0C11E27A90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output =  [[-142.03171  -172.64523     0.        -61.611305 -178.14746  -176.38095\n",
      "  -149.58891  -169.29485   -96.73183  -165.3873  ]]\n",
      "The digit is classified as  2\n",
      "Image 2:\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAABm0lEQVR4nGWSQWsTURSFz70zUYRCLRVSaUlFIRUEbfMHhEpx50LqtsWtoHt37l1mkV/QLt2IILiI4rIQxGgpNJpYbCNtY2iraMO8e7p4ybwZvZs3Mx/ce+43TwgAMH8oBJkSAmD4RFPJQYrtHscUuzBdAOBSHAOg2FbzYqLcGR+bKZcjmGbaggMngB72f375WF6cG83xMFN79feVBxOeSjatiADorrefTnvKXJlzJNeeDWgkNd9UVC3Bvc4mCOAfCBhiHGJiuHVoaeackfzx6AVpJAO04dl7+XDN/Ftmld5BQSX52sDSfOTDxmFa++3xa9fAq7tRTvwwip7sSXfjXLF05bJ39J+h01bzW2f5jqf5tImR5IeVN2RIay44MrK5uk83MkRJZYhKguuVHaSG5M9vhOEKnUQKiU+1U7GQiv53q/dZfLeNFBKSJClUlJ5U+/EwlAG9jckUiuH2ped/IxEAotFR7cZVhD0d+4/vfx548/Xl6i9aRrzp0Xr92sIUtdWYurV0Pq+Pgt73louT+OZsAbkLhty1Hz2fAW38JkbPr/dOAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=28x28 at 0x7F0C11DA5630>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output =  [[-105.85771 -124.99865    0.       -21.94822 -152.93634  -68.16041\n",
      "   -86.98468 -134.10194  -72.43932 -145.65083]]\n",
      "The digit is classified as  2\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from IPython.display import display\n",
    "from PIL import Image\n",
    "\n",
    "print('Image 1:')\n",
    "img = Image.open('assets/two.png').resize((28, 28)).convert('L')\n",
    "display(img)\n",
    "output = tf_rep.run(np.asarray(img, dtype=np.float32)[np.newaxis, np.newaxis, :, :])\n",
    "print('output = ',  output._0)\n",
    "print('The digit is classified as ', np.argmax(output))\n",
    "\n",
    "print('Image 2:')\n",
    "img = Image.open('assets/three.png').resize((28, 28)).convert('L')\n",
    "display(img)\n",
    "output = tf_rep.run(np.asarray(img, dtype=np.float32)[np.newaxis, np.newaxis, :, :])\n",
    "print('output = ',  output._0)\n",
    "print('The digit is classified as ', np.argmax(output))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the model into a file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_rep.export_graph('mnist.pb')"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
